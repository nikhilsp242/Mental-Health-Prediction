{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0774f5c",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "777aa68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines  #for reading/writing the files\n",
    "import re   #for cleaning\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize  #for tokenization\n",
    "from nltk.corpus import stopwords   #for stopwords removal\n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "import spacy  #for lemmatization\n",
    "from keras.preprocessing.sequence import pad_sequences   #for padding sequences\n",
    "from gensim.models import Word2Vec  #for word embedding\n",
    "from sklearn.preprocessing import LabelEncoder  #for label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01950d17",
   "metadata": {},
   "source": [
    "## Path to Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695e258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the input JL files\n",
    "train_ip_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/SMHDv1.1/SMHD_train.jl/train.jl'\n",
    "test_ip_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/SMHDv1.1/SMHD_test.jl/test.jl'\n",
    "dev_ip_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/SMHDv1.1/SMHD_dev.jl/dev.jl'\n",
    "\n",
    "sample_input = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/sample1000.jl'\n",
    "sample_output = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/sample1000text.jl'\n",
    "\n",
    "# Path to the output JL files\n",
    "train_op_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/trainText.jl'\n",
    "test_op_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/testText.jl'\n",
    "dev_op_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/devText.jl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99b0df",
   "metadata": {},
   "source": [
    " # 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4da326",
   "metadata": {},
   "source": [
    "## Keep only text and remove titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b2dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_text(input_jl_file_path,output_jl_file_path) :\n",
    "    with jsonlines.open(input_jl_file_path) as reader:\n",
    "        # Create a list to store modified user data\n",
    "        modified_users = []\n",
    "\n",
    "        # Iterate through each line in the input JL file\n",
    "        for user_data in reader:\n",
    "            # Create a new dictionary for the user data without \"text\" section in each post\n",
    "            modified_user_data = {\n",
    "                \"id\": user_data[\"id\"],\n",
    "                \"label\": user_data[\"label\"],\n",
    "                \"posts\": []\n",
    "            }\n",
    "\n",
    "            # Iterate through each post in the user's data\n",
    "            for post in user_data[\"posts\"]:\n",
    "                modified_post = {\n",
    "                    \"created_utc\": post[\"created_utc\"]\n",
    "                }\n",
    "\n",
    "                # Check if the post is a comment or an ownpost\n",
    "                if \"text\" in post:\n",
    "                    modified_post[\"text\"] = post[\"text\"]\n",
    "\n",
    "                modified_user_data[\"posts\"].append(modified_post)\n",
    "\n",
    "            # Add the modified user data to the list\n",
    "            modified_users.append(modified_user_data)\n",
    "\n",
    "    # Write the modified user data to the output JL file\n",
    "    with jsonlines.open(output_jl_file_path, mode='w') as writer:\n",
    "        writer.write_all(modified_users)\n",
    "    \n",
    "    print(\"Data copied and modified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437e94f",
   "metadata": {},
   "source": [
    "### (try on sample data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde7a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data copied and modified successfully!\n"
     ]
    }
   ],
   "source": [
    "keep_only_text(sample_input,sample_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31433c02",
   "metadata": {},
   "source": [
    "### (a) train.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06bd88d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data copied and modified successfully!\n"
     ]
    }
   ],
   "source": [
    "keep_only_text(train_ip_path,train_op_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d91922d",
   "metadata": {},
   "source": [
    "### (b) test.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf30c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data copied and modified successfully!\n"
     ]
    }
   ],
   "source": [
    "keep_only_text(test_ip_path,test_op_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8128df6",
   "metadata": {},
   "source": [
    "### (c) dev.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448bed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data copied and modified successfully!\n"
     ]
    }
   ],
   "source": [
    "keep_only_text(dev_ip_path,dev_op_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123f0bf",
   "metadata": {},
   "source": [
    "## path to new modified files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e81d5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the output JL files\n",
    "train_ip_text = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/trainText.jl'\n",
    "test_ip_text = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/testText.jl'\n",
    "dev_ip_text = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/devText.jl'\n",
    "\n",
    "sample_file = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/sampleLemma1000.jl'\n",
    "\n",
    "model_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/Model/Sampleword2vec.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469a201",
   "metadata": {},
   "source": [
    "## Load all the data to data frames "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec127f05",
   "metadata": {},
   "source": [
    "#####  sample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16efb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = []\n",
    "with open(sample_file, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        sample_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659292a",
   "metadata": {},
   "source": [
    "##### (a) train.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2ccf05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with open(train_ip_text, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        train_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a75923",
   "metadata": {},
   "source": [
    "##### (b) test.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b30ef65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with open(test_ip_text, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        test_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f18628",
   "metadata": {},
   "source": [
    "##### (c) dev.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002c63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "with open(dev_ip_text, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        val_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd3bbc2",
   "metadata": {},
   "source": [
    "## Remove punctuations , mentions , hashtags , etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b5f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove non-alphabetical characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove words starting with @ or #\n",
    "    text = re.sub(r'[@#]\\w+', '', text)\n",
    "    # Remove links (http and https)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'http\\w+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c86ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    for user_data in data:\n",
    "        for post in user_data['posts']:\n",
    "            if 'text' in post:\n",
    "                post['text'] = clean_text(post['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5b7cd",
   "metadata": {},
   "source": [
    "### (try on sample data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d6a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3059ee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1390913029,\n",
       " 'text': 'Unfortunately Charizard is pretty bad wo mega in addition to that you really need a rapid spinner other wise itll be hard to switch him in at all Switching your megastone from aggron to charizard or just ditching charizard would help You have a lot of fast but frail sweepersjolteon espeon greninja Id recommend switching Greninja to a bulky watertype like vaporeon milotic jellicent or if you insist on keeping charizard blastoisetentacruel for rapid spin support Right now your team is incredibly frail on the physical side bar Aggron and none of them can take any powerful special hit'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[999]['posts'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943a862",
   "metadata": {},
   "source": [
    "### (a) train.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b72c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "066171e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1507313988,\n",
       " 'text': 'Probably weed but maby kratom lsd or shrooms'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['posts'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb2d9f",
   "metadata": {},
   "source": [
    "### (b) test.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "957314d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0656e0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1412904040,\n",
       " 'text': 'For people who like Sandersons books its great Its right up there with the best hes written in my opinion If any of you havent read anything by Sanderson this is a good place to start '}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]['posts'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860852ce",
   "metadata": {},
   "source": [
    "### (c) dev.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c1d0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1b0892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1417511828,\n",
       " 'text': 'Their posts are always fucking hilarious dunno why people find it so annoying not like youre going to find anything useful in the youtube comments anyway'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0]['posts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c366f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181a7cb6",
   "metadata": {},
   "source": [
    "# 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389a91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a91e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    for user_data in data:\n",
    "        for post in user_data['posts']:\n",
    "            if 'text' in post:\n",
    "                post['text'] = word_tokenize(post['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60ea3f",
   "metadata": {},
   "source": [
    "### (try on sample data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3fe2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1264b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1389671029,\n",
       " 'text': ['Added', 'really', 'need', 'that', 'larvesta', 'D']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[999]['posts'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ca5b8",
   "metadata": {},
   "source": [
    "### (a) train.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012001ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c1d45c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1507313988,\n",
       " 'text': ['Probably', 'weed', 'but', 'maby', 'kratom', 'lsd', 'or', 'shrooms']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['posts'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd79bc0",
   "metadata": {},
   "source": [
    "### (b) test.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32039e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83cead2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8453925",
   "metadata": {},
   "source": [
    "### (c) dev.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98783ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852691cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11f3590",
   "metadata": {},
   "source": [
    "# 3. Removal of Stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9336c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up NLTK stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddba6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_stop_words(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17d3b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokenized_data):\n",
    "    for user_data in tokenized_data:\n",
    "        for post in user_data['posts']:\n",
    "            post['text'] = handle_stop_words(post['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a3b03",
   "metadata": {},
   "source": [
    "### (try on sample data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a8fd8",
   "metadata": {},
   "source": [
    "##### Before removal of stops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0852810b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1389671029,\n",
       " 'text': ['Added', 'really', 'need', 'that', 'larvesta', 'D']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[999]['posts'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f34494cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d0677",
   "metadata": {},
   "source": [
    "##### After removal of stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9983b094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1389671029, 'text': ['Added', 'really', 'need', 'larvesta']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[999]['posts'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4199c4",
   "metadata": {},
   "source": [
    "### (a) train.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f8d58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7d741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d91c4ae",
   "metadata": {},
   "source": [
    "### (b) test.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2217af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d781f5f2",
   "metadata": {},
   "source": [
    "### (c) dev.jl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e59dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99b8eec7",
   "metadata": {},
   "source": [
    "# 4. Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2684e12",
   "metadata": {},
   "source": [
    "## Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f69be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nikhil\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3177ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizer = WordNetLemmatizer()  #bad results, fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b37efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")  #better results, slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fe58699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    doc = nlp(\" \".join(text))\n",
    "    normalized_tokens = [token.lemma_ for token in doc]\n",
    "    return normalized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd908eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tokenized_data):\n",
    "    for user_data in tokenized_data:\n",
    "        for post in user_data['posts']:\n",
    "            post['text'] = normalize_text(post['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582e0a5",
   "metadata": {},
   "source": [
    "##### Before Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8ef3e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1372630153,\n",
       " 'text': ['really', 'hoping', 'got', 'head', 'option', 'wear']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[999]['posts'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f09dfc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623287d",
   "metadata": {},
   "source": [
    "##### After Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b42e5ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1372630153,\n",
       " 'text': ['really', 'hope', 'get', 'head', 'option', 'wear']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[999]['posts'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb567259",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/sampleLemma1000.jl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1e8a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    for item in sample_data:\n",
    "        new_file.write(json.dumps(item, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf35748",
   "metadata": {},
   "source": [
    "# 5. Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624c7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "376e3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa7d20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_data in sample_data:\n",
    "    for post in user_data['posts']:\n",
    "        for word in post['text']:\n",
    "            if word not in word_index:\n",
    "                word_index[word] = current_index\n",
    "                current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f7928e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59bc8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_data in sample_data:\n",
    "    for post in user_data['posts']:\n",
    "        num_words = len(post['text'])\n",
    "        if num_words > max_sequence_length:\n",
    "            max_sequence_length = num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72883feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n"
     ]
    }
   ],
   "source": [
    "print(max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84d5010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "933c2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_data in sample_data:\n",
    "    user_sequences = [post['text'] for post in user_data['posts']]\n",
    "    \n",
    "    # Convert text to integer sequences using the word-to-index mapping\n",
    "    user_sequences = [[word_index.get(word, 0) for word in post] for post in user_sequences]\n",
    "    \n",
    "    # Pad integer sequences to the defined maximum length\n",
    "    padded_user_sequences = pad_sequences(user_sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    padded_sequences.append(padded_user_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37b5357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = 999\n",
    "post_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81bc398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_padded_sequence = padded_sequences[user_index][post_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed905a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 999, Post 1 Padded Sequence: [   0    0    0 ...  138  349 2150]\n"
     ]
    }
   ],
   "source": [
    "print(f\"User {user_index}, Post {post_index} Padded Sequence: {user_padded_sequence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29357016",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/Sample_padding_sequence.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4026b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = [np_array.tolist() for np_array in padded_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75e0a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(padded_sequences, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac18410",
   "metadata": {},
   "source": [
    "# 6. Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c2f687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {index: word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d5d3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76cdaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_sequences in padded_sequences:\n",
    "    user_sentences = []\n",
    "    for sequence in user_sequences:\n",
    "        words = [reverse_word_index.get(word_index, '') for word_index in sequence]\n",
    "        # Filter out empty strings (words that were not in the vocabulary)\n",
    "        words = [word for word in words if word]\n",
    "        user_sentences.extend(words)\n",
    "    sentences.append(user_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccbd9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "439eefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=sentences, vector_size=embedding_dim, window=5, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59e70662",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "610eec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = word2vec_model.wv['kill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abbfc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = word2vec_model.wv.most_similar('kill', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c640dd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Vector: [-0.7624603   0.5667327  -0.11790708  0.4045255   1.6707231  -0.93970895\n",
      " -1.1593304  -0.34688106  0.9544053  -0.43721533  0.7584189  -0.47916892\n",
      " -0.59194493 -0.2209195  -0.06403993 -0.4531901   2.1844497  -1.5598427\n",
      " -1.6020402  -1.0974357   1.4175241   0.9730563   0.0496596   0.22842279\n",
      " -1.2254587   2.339027   -1.1140791   1.06785    -1.8779273  -0.03106171\n",
      " -0.40430018 -2.5592191   1.9469364  -0.97656447 -1.5017256   0.5677096\n",
      "  1.0405535  -1.5106094  -2.3751135  -1.7575663  -2.8695605  -1.225546\n",
      " -1.7039794   0.0600432   0.36928493  0.59420407  0.69251025 -1.2156699\n",
      "  0.8187086   0.682567    0.9484843  -0.44280767  0.42827117 -0.35138822\n",
      "  1.1773863   0.7543728  -0.9010412  -0.21494429 -1.5918437  -0.33065182\n",
      "  1.5333589  -2.2780867  -0.68316287  0.27214384  0.09200618  0.43474734\n",
      " -1.8963821  -0.4905794  -0.02900872  1.759124   -1.4844135  -0.13969484\n",
      "  2.1848798  -1.441671   -0.9977914  -0.55889696 -1.8839258  -1.2839987\n",
      " -0.0566964  -2.023728   -0.9764239  -0.577979   -1.102027    1.2699846\n",
      "  0.53897566  0.1398392   1.3257358   0.734132    1.2448078   1.1269165\n",
      "  0.86191404 -0.55766034  1.4943216   0.58206344  1.0625005  -0.5828765\n",
      " -0.7511615   0.14331856  3.2008104  -1.130513  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Vector:\", word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59ed5c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Words: [('destroy', 0.7499843835830688), ('attack', 0.7377498745918274), ('chase', 0.7375485301017761), ('strike', 0.737365186214447), ('fight', 0.7349938750267029)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Similar Words:\", similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49821a",
   "metadata": {},
   "source": [
    "# 7. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b70669c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "601c2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_data in sample_data:\n",
    "    user_labels = user_data.get('label', [])  \n",
    "    # Extend the set with the user's labels\n",
    "    all_labels.update(user_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "68dc7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_list = list(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81f29a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anxiety', 'autism', 'ptsd', 'adhd', 'bipolar', 'eating', 'depression', 'ocd', 'control']\n"
     ]
    }
   ],
   "source": [
    "print(all_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4396a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "07bd0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "67591557",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = all_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "088493ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = label_encoder.fit_transform(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aabe2fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c3de801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mapping between original labels and their encoded values\n",
    "label_mapping = dict(zip(target_labels, encoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4b04497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anxiety': 1, 'autism': 2, 'ptsd': 8, 'adhd': 0, 'bipolar': 3, 'eating': 6, 'depression': 5, 'ocd': 7, 'control': 4}\n"
     ]
    }
   ],
   "source": [
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fca7a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/Sample_label_encoding.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a3076dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mappings = {label: int(encoded_label) for label, encoded_label in zip(target_labels, label_encoder.transform(target_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "18cd4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(label_mappings, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4637c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef149032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "22bd198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_path = 'C:/Users/nikhil/PESU/Capstone/Data/SMHD/sampleLabEnc1000.jl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "75848b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    for item in sample_data:\n",
    "        new_file.write(json.dumps(item, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d961ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
